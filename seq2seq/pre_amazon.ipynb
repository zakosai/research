{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim\n",
    "import os\n",
    "data_dir = \"data/Garden\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, \"rb\")\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "        \n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1308614400</td>\n",
       "      <td>Carter H \"1amazonreviewer@gmail . com\"</td>\n",
       "      <td>Great Hoses</td>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>Good USA company that stands behind their prod...</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>06 21, 2011</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1402272000</td>\n",
       "      <td>Darryl Bennett \"Fuzzy342\"</td>\n",
       "      <td>Gilmour 10-58050 8-ply Flexogen Hose 5/8-Inch ...</td>\n",
       "      <td>A32JCI4AK2JTTG</td>\n",
       "      <td>This is a high quality 8 ply hose. I have had ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>06 9, 2014</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1336176000</td>\n",
       "      <td>H B</td>\n",
       "      <td>Very satisfied!</td>\n",
       "      <td>A3N0P5AAMP6XD2</td>\n",
       "      <td>It's probably one of the best hoses I've ever ...</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>05 5, 2012</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373846400</td>\n",
       "      <td>Jason</td>\n",
       "      <td>Very high quality</td>\n",
       "      <td>A2QK7UNJ857YG</td>\n",
       "      <td>I probably should have bought something a bit ...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>07 15, 2013</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1375660800</td>\n",
       "      <td>jimmy</td>\n",
       "      <td>Good Hoses</td>\n",
       "      <td>AS0CYBAN6EM06</td>\n",
       "      <td>I bought three of these 5/8-inch Flexogen hose...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>08 5, 2013</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unixReviewTime                            reviewerName  \\\n",
       "0      1308614400  Carter H \"1amazonreviewer@gmail . com\"   \n",
       "1      1402272000               Darryl Bennett \"Fuzzy342\"   \n",
       "2      1336176000                                     H B   \n",
       "3      1373846400                                   Jason   \n",
       "4      1375660800                                   jimmy   \n",
       "\n",
       "                                             summary      reviewerID  \\\n",
       "0                                        Great Hoses  A1JZFGZEZVWQPY   \n",
       "1  Gilmour 10-58050 8-ply Flexogen Hose 5/8-Inch ...  A32JCI4AK2JTTG   \n",
       "2                                    Very satisfied!  A3N0P5AAMP6XD2   \n",
       "3                                  Very high quality   A2QK7UNJ857YG   \n",
       "4                                         Good Hoses   AS0CYBAN6EM06   \n",
       "\n",
       "                                          reviewText helpful   reviewTime  \\\n",
       "0  Good USA company that stands behind their prod...  [4, 4]  06 21, 2011   \n",
       "1  This is a high quality 8 ply hose. I have had ...  [0, 0]   06 9, 2014   \n",
       "2  It's probably one of the best hoses I've ever ...  [2, 3]   05 5, 2012   \n",
       "3  I probably should have bought something a bit ...  [0, 0]  07 15, 2013   \n",
       "4  I bought three of these 5/8-inch Flexogen hose...  [1, 1]   08 5, 2013   \n",
       "\n",
       "         asin  overall  \n",
       "0  B00002N674      4.0  \n",
       "1  B00002N674      5.0  \n",
       "2  B00002N674      4.0  \n",
       "3  B00002N674      5.0  \n",
       "4  B00002N674      5.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = getDF(\"data/Garden/reviews.json.gz\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching user, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# num of user: 1686 \n",
      "# num of item: 962\n"
     ]
    }
   ],
   "source": [
    "item_unique = sorted(data.asin.unique())\n",
    "user_unique = sorted(data.reviewerID.unique())\n",
    "print(\"# num of user: %d \\n# num of item: %d\"%(len(user_unique), len(item_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data following user\n",
    "\n",
    "n_user = len(user_unique)\n",
    "n_item = len(item_unique)\n",
    "\n",
    "previous_user_id = 0\n",
    "ratings = [0] * n_user\n",
    "f = open(\"%s/ratings.txt\"%data_dir, \"w\")\n",
    "for _, r in data.iterrows():\n",
    "    uid = user_unique.index(r.reviewerID)\n",
    "    iid = item_unique.index(r.asin)\n",
    "    if ratings[uid] == 0:\n",
    "        ratings[uid] = [[iid, r.overall, r.reviewTime]]\n",
    "    else:\n",
    "        ratings[uid].append([iid, r.overall, r.reviewTime])\n",
    "    f.write(\"%d::%i::%d::%s\\n\"%(uid, iid, int(r.overall), r.reviewTime))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max item user rated: 66\n",
      "Min item user rated: 5\n",
      "Mean item user rated: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Max item user rated: %d\"%max([len(i) for i in ratings]))\n",
    "print(\"Min item user rated: %d\"%min([len(i) for i in ratings]))\n",
    "print(\"Mean item user rated: %d\"%np.mean([len(i) for i in ratings]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write new id of items into file\n",
    "f = open(\"%s/item_id.txt\"%data_dir, \"w\")\n",
    "f.write(\"\\n\".join(item_unique))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write new id of users into file\n",
    "f = open(\"%s/user_id.txt\"%data_dir, \"w\")\n",
    "f.write(\"\\n\".join(user_unique))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_id = np.random.permutation(n_user)\n",
    "train_len = int(0.7*n_user)\n",
    "train_id = shuffle_id[:train_len]\n",
    "test_id = shuffle_id[train_len:]\n",
    "\n",
    "ftrain = open(\"%s/implicit/train.txt\"%data_dir, \"w\")\n",
    "for idx in train_id:\n",
    "    user = np.array(ratings[idx]).reshape((len(ratings[idx]), 3))\n",
    "    user = user[np.argsort(user[:, 2])]\n",
    "    item = list(user[:, 0])\n",
    "    item = [str(i) for i in item]\n",
    "    ftrain.write(\"%d %s\\n\"%(idx, \" \".join(item)))\n",
    "ftrain.close()\n",
    "\n",
    "ftest = open(\"%s/implicit/test.txt\"%data_dir, \"w\")\n",
    "for idx in test_id:\n",
    "    user = np.array(ratings[idx]).reshape((len(ratings[idx]), 3))\n",
    "    user = user[np.argsort(user[:, 2])]\n",
    "    item = list(user[:, 0])\n",
    "    item = [str(i) for i in item]\n",
    "    ftest.write(\"%d %s\\n\"%(idx, \" \".join(item)))\n",
    "ftest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create item description for cf-vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>asin</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'also_viewed': ['0761149430', '0761120149', '...</td>\n",
       "      <td>Steven Raichlen's Best of Barbecue Primal Gril...</td>\n",
       "      <td>[[Patio, Lawn &amp; Garden, Grills &amp; Outdoor Cooki...</td>\n",
       "      <td>Primal Grill with Steven Raichlen, Volume One</td>\n",
       "      <td>{'Movies &amp; TV': 231134}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51cNn5Dl...</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'also_viewed': ['B008WC0X0A', 'B000CPMOVG', '...</td>\n",
       "      <td>The Tesoro Sand Shark metal combines time-prov...</td>\n",
       "      <td>[[Patio, Lawn &amp; Garden, Lawn Mowers &amp; Outdoor ...</td>\n",
       "      <td>Sand Shark Margare Maron Audio CD</td>\n",
       "      <td>{'Patio, Lawn &amp; Garden': 188289}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31B9X0S6...</td>\n",
       "      <td>144072007X</td>\n",
       "      <td>577.15</td>\n",
       "      <td>Tesoro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'also_viewed': ['1554701511', '1554702720'], ...</td>\n",
       "      <td>This definitive guide to incorporating planks ...</td>\n",
       "      <td>[[Patio, Lawn &amp; Garden, Grills &amp; Outdoor Cooki...</td>\n",
       "      <td>Napoleon's Everyday Plank Grilling</td>\n",
       "      <td>{'Patio, Lawn &amp; Garden': 196610}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51cTWw9d...</td>\n",
       "      <td>1554701503</td>\n",
       "      <td>26.39</td>\n",
       "      <td>Napoleon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'also_viewed': ['1250039479', '1250010160', '...</td>\n",
       "      <td>This is a Bad Kitty backpack pull clip.</td>\n",
       "      <td>[[Patio, Lawn &amp; Garden, Picnic Baskets &amp; Acces...</td>\n",
       "      <td>Bad Kitty Backpack Pull</td>\n",
       "      <td>{'Toys &amp; Games': 183251}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41nR62o%...</td>\n",
       "      <td>1579822932</td>\n",
       "      <td>3.65</td>\n",
       "      <td>Bad Kitty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'also_viewed': ['B005EN5008', 'B007ZU4BV2', '...</td>\n",
       "      <td>Every spa needs to be shocked to eliminate und...</td>\n",
       "      <td>[[Patio, Lawn &amp; Garden, Pools, Hot Tubs &amp; Supp...</td>\n",
       "      <td>5 pound SpaGuard Enhanced Spa Shock</td>\n",
       "      <td>{'Patio, Lawn &amp; Garden': 80211}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/21cOwSPt...</td>\n",
       "      <td>1754164498</td>\n",
       "      <td>29.99</td>\n",
       "      <td>SpaGuard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             related  \\\n",
       "0  {'also_viewed': ['0761149430', '0761120149', '...   \n",
       "1  {'also_viewed': ['B008WC0X0A', 'B000CPMOVG', '...   \n",
       "2  {'also_viewed': ['1554701511', '1554702720'], ...   \n",
       "3  {'also_viewed': ['1250039479', '1250010160', '...   \n",
       "4  {'also_viewed': ['B005EN5008', 'B007ZU4BV2', '...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Steven Raichlen's Best of Barbecue Primal Gril...   \n",
       "1  The Tesoro Sand Shark metal combines time-prov...   \n",
       "2  This definitive guide to incorporating planks ...   \n",
       "3            This is a Bad Kitty backpack pull clip.   \n",
       "4  Every spa needs to be shocked to eliminate und...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [[Patio, Lawn & Garden, Grills & Outdoor Cooki...   \n",
       "1  [[Patio, Lawn & Garden, Lawn Mowers & Outdoor ...   \n",
       "2  [[Patio, Lawn & Garden, Grills & Outdoor Cooki...   \n",
       "3  [[Patio, Lawn & Garden, Picnic Baskets & Acces...   \n",
       "4  [[Patio, Lawn & Garden, Pools, Hot Tubs & Supp...   \n",
       "\n",
       "                                           title  \\\n",
       "0  Primal Grill with Steven Raichlen, Volume One   \n",
       "1              Sand Shark Margare Maron Audio CD   \n",
       "2             Napoleon's Everyday Plank Grilling   \n",
       "3                        Bad Kitty Backpack Pull   \n",
       "4            5 pound SpaGuard Enhanced Spa Shock   \n",
       "\n",
       "                          salesRank  \\\n",
       "0           {'Movies & TV': 231134}   \n",
       "1  {'Patio, Lawn & Garden': 188289}   \n",
       "2  {'Patio, Lawn & Garden': 196610}   \n",
       "3          {'Toys & Games': 183251}   \n",
       "4   {'Patio, Lawn & Garden': 80211}   \n",
       "\n",
       "                                               imUrl        asin   price  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51cNn5Dl...  0981850006     NaN   \n",
       "1  http://ecx.images-amazon.com/images/I/31B9X0S6...  144072007X  577.15   \n",
       "2  http://ecx.images-amazon.com/images/I/51cTWw9d...  1554701503   26.39   \n",
       "3  http://ecx.images-amazon.com/images/I/41nR62o%...  1579822932    3.65   \n",
       "4  http://ecx.images-amazon.com/images/I/21cOwSPt...  1754164498   29.99   \n",
       "\n",
       "       brand  \n",
       "0        NaN  \n",
       "1     Tesoro  \n",
       "2   Napoleon  \n",
       "3  Bad Kitty  \n",
       "4   SpaGuard  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item = getDF(\"%s/meta.json.gz\"%data_dir)\n",
    "data_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962\n"
     ]
    }
   ],
   "source": [
    "data_item = data_item[data_item.asin.isin(item_unique)]\n",
    "print(len(data_item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "list_cat = []\n",
    "for i in item_unique:\n",
    "    d = data_item[data_item.asin == i]\n",
    "    text += (d.title + d.description).tolist()\n",
    "    list_cat.append(d.categories.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write file\n",
    "text = [gensim.utils.simple_preprocess(str(t)) for t in text]\n",
    "text = [' '.join(t) for t in text]\n",
    "f = open(\"%s/description_fix.txt\"%data_dir, \"w\")\n",
    "f.write(\"\\n\".join(text))\n",
    "f.close()\n",
    "\n",
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import save_npz\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text)\n",
    "save_npz(\"%s/item.npz\"%data_dir, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = data_item.categories.tolist()\n",
    "categories = [i for cat in categories for c in cat for i in c]\n",
    "categories = list(set(categories))\n",
    "len(categories)\n",
    "\n",
    "f = open(\"%s/categories.txt\"%data_dir, \"w\")\n",
    "for c in list_cat:\n",
    "    arr = ['0']*len(categories)\n",
    "    for i in c[0][0]:\n",
    "        arr[categories.index(i)] = '1'\n",
    "    f.write(\",\".join(arr))\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4]\n",
    "l[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
